# ðŸ§  NLP Language Modeling Project â€” Aishwarya Bhethanabotla

This repository contains implementations of statistical and neural language models for sequence prediction, developed as part of an NLP course assignment. It includes N-gram language models with smoothing techniques and an RNN-based Seq2Seq model, all evaluated using perplexity.

---

## ðŸ“š Project Objectives

1. **Implement Unigram and Bigram Models**:
   - Count unigram and bigram frequencies from a training dataset.
2. **Apply Smoothing Techniques**:
   - Implement **Good-Turing** and **Kneser-Ney** smoothing for unseen n-grams.
3. **Evaluate Using Perplexity**:
   - Prove and implement the perplexity metric:  
     \[
     \text{Perplexity} = e^{\frac{\text{Total Loss}}{\text{Number of Predictions}}}
     \]
4. **Build a Neural Language Model**:
   - Construct an RNN-based Seq2Seq model using TensorFlow/Keras.
   - Include padding, sequence loss, and prediction decoding.
5. **Analyze Performance**:
   - Compare performance and predictions of N-gram vs RNN-based models.

---

## ðŸ“‚ File Structure


---

## âœ… Features Implemented

| Feature | Status |
|--------|--------|
| Unigram and Bigram Calculation | âœ… Done |
| Bigram Model | âœ… Done |
| Good-Turing Smoothing | âœ… Done |
| Kneser-Ney Smoothing | âœ… Done |
| Perplexity Proof | âœ… Done |
| Perplexity Calculation | âœ… Done |
| Prediction Function | âœ… Done |
| Sentence Padding | âœ… Done |
| RNN Model | âœ… Done |
| Seq2Seq Loss | âœ… Done |
| Prediction Outputs | âœ… Done |
| Model Comparison Analysis | âœ… Done |

---

## ðŸ“Š Results Overview

- **N-gram Models**: Fast and interpretable, but suffer with data sparsity.
- **RNN Models**: Better performance on longer and unseen sequences.
- **Perplexity**: Quantitative evaluation showed RNN outperforming bigrams on held-out test data.

---

## ðŸ’» Usage Instructions

1. Open the `A3_Bhethanabotla_Aishwarya!!.ipynb` notebook in Jupyter or Google Colab.
2. Run all cells sequentially to see training, predictions, and evaluation.
3. All code is self-contained in the notebook.

---

## ðŸ“¬ Contact

**Aishwarya Bhethanabotla**  
M.S. Computer Science (AI) â€” Stevens Institute of Technology  
GitHub: [Aish970](https://github.com/Aish970)  
LinkedIn: [linkedin.com/in/aishwaryabhethanabotla](https://linkedin.com/in/aishwaryabhethanabotla)

